---
title: "Latent Action Pretraining Through World Modeling"
collection: publications
permalink: /publication/2025-lawm
excerpt: 'Teaching robots from human videos through self-supervised world modeling'
date: 2025-01-15
venue: 'Submitted to ICRA 2026'
paperurl: 'https://arxiv.org/abs/2509.18428'
citation: 'Bahey Tharwat, Yara Nasser, Ali Abouzied, Ian Reid. (2025). "Latent Action Pretraining Through World Modeling." <i>arXiv preprint arXiv:2509.18428</i>.'
---

Vision-Language-Action (VLA) models enable robots to follow language instructions but often require large labeled datasets. We propose LAWM, a model-agnostic framework that learns latent actions through world modeling from unlabeled videos.

Supervised by Prof. Ian D. Reid at Mohamed bin Zayed University of Artificial Intelligence (MBZUAI).

[Download paper here](https://arxiv.org/abs/2509.18428)
